<p align="center">
  <h3 align="center"><strong>DeepMesh: Auto-Regressive Artist-Mesh Creation<br>With Reinforcement Learning</strong></h3>

<p align="center">
    <a href="https://zhaorw02.github.io/">Ruowen Zhao</a><sup>1,2*</sup>,
    <a href="https://jamesyjl.github.io/">Junliang Ye</a><sup>1,2*</sup>,
    <a href="https://thuwzy.github.io/">Zhengyi Wang</a><sup>1,2*</sup>,<br>
    <a href="">Guangce Liu</a><sup>2</sup>,
    <a href="https://buaacyw.github.io/">Yiwen Chen</a><sup>3</sup>,
    <a href="https://yikaiw.github.io/">Yikai Wang</a><sup>1</sup>,
    <a href="https://ml.cs.tsinghua.edu.cn/~jun/index.shtml">Jun Zhu</a><sup>1,2â€ </sup>
    <br>
    <sup>*</sup>Equal Contribution.
    <br>
    <sup>â€ </sup>Corresponding authors.
    <br>
    <sup>1</sup>Tsinghua University,
    <sup>2</sup>ShengShu,
    <br>
    <sup>3</sup>S-Lab, Nanyang Technological University,
</p>


<div align="center">

<a href='https://arxiv.org/abs/2503.15265'><img src='https://img.shields.io/badge/arXiv-2503.15265-b31b1b.svg'></a> &nbsp;&nbsp;&nbsp;&nbsp;
 <a href='https://zhaorw02.github.io/DeepMesh/'><img src='https://img.shields.io/badge/Project-Page-Green'></a> &nbsp;&nbsp;&nbsp;&nbsp;
 <a><img src='https://img.shields.io/badge/License-MIT-blue'></a> &nbsp;&nbsp;&nbsp;&nbsp;
<a href="https://huggingface.co/zzzrw/DeepMesh/tree/main"><img src="https://img.shields.io/badge/%F0%9F%A4%97%20Weights-HF-orange"></a> &nbsp;&nbsp;&nbsp;&nbsp;
<a href='https://www.youtube.com/watch?v=6grL7bSbQ2w'><img src='https://img.shields.io/badge/Youtube-Video-b31b1b.svg'>

</div>


<div align="center">

<img src="assets/teaser.png" alt="Demo" width="1024px" />

</div>

**All of the meshes above are generated by DeepMesh.** DeepMesh can generate high-quality meshes conditioned on the given point cloud by auto-regressive transformer.


## Release
- [3/20] ðŸ”¥ðŸ”¥We released the pretrained weight of **DeepMesh** (0.5 B).
- [4/01] ðŸ”¥We optimized the inference code, achieving a 50% reduction in generation time.

## Contents
- [Release](#release)
- [Installation](#installation)
- [Usage](#usage)
- [Important Notes](#important-notes)
- [Todo](#todo)
- [Acknowledgement](#acknowledgement)
- [BibTeX](#bibtex)

## Installation
Our environment has been tested on Ubuntu 22, CUDA 11.8 with A100, A800 and A6000.
1. Clone our repo and create conda environment
```
git clone https://github.com/zhaorw02/DeepMesh.git && cd DeepMesh
conda env create -f environment.yaml
conda activate deepmesh
```
or you can create on CUDA 12.1.
```
conda create -n deepmesh python=3.12
pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu121
pip3 install -U xformers --index-url https://download.pytorch.org/whl/cu121
git clone https://github.com/Dao-AILab/flash-attention
cd flash-attention
pip install packaging
python setup.py install
cd csrc/rotary && pip install .
cd ../layer_norm && pip install .
cd ../xentropy && pip install .
cd ../../.. && rm -r flash-attention
pip install trimesh beartype lightning safetensors open3d omegaconf sageattention triton scikit-image transformers
conda activate deepmesh
```

2. Install the pretrained model weight
```
pip install -U "huggingface_hub[cli]"
huggingface-cli login
huggingface-cli download zzzrw/DeepMesh --local-dir ./
```

## Usage
### Command line inference
```
# Note: if you want to use your own point cloud, please make sure the normal is included.

# Generate all obj/ply in your folder
CUDA_VISIBLE_DEVICES=0 torchrun --nproc-per-node=1 --master_port=12345 sample.py \
    --model_path "your_model_path" \
    --steps 90000 \
    --input_path examples \
    --output_path mesh_output \
    --repeat_num 4 \
    --temperature 0.5 \

# Generate the specified obj/ply in your folder
CUDA_VISIBLE_DEVICES=0 torchrun --nproc-per-node=1 --master_port=22345.py \
    --model_path "your_model_path" \
    --steps 90000 \
    --input_path examples \
    --output_path mesh_output \
    --repeat_num 4 \
    --uid_list "wand1.obj,wand2.obj,wand3.ply" \
    --temperature 0.5 \

# Or
bash sample.sh
```
## Important Notes
- Please refer to our [project_page](https://zhaorw02.github.io/DeepMesh/) for more examples.
## Todo
- [ ] Release of pre-training code  ( truncted sliding training ).
- [ ] Release of post-training code ( DPO ).
- [ ] Release of larger model ( 1b version ).

## Acknowledgement
Our code is based on these wonderful repos:
* **[BPT](https://github.com/whaohan/bpt)**
* **[LLaMA-Mesh](https://github.com/nv-tlabs/LLaMa-Mesh)**
* **[SMDM](https://github.com/ML-GSAI/SMDM)**
* [Meshanything V2](https://github.com/buaacyw/MeshAnythingV2/tree/main)
* [Michelangelo](https://github.com/NeuralCarver/Michelangelo)

Also we invite you to explore our latest work [ShapeLLM-Omni](https://github.com/JAMESYJL/ShapeLLM-Omni) â€”â€” a native multimodal LLM for 3D generation and understanding.
## BibTeX
```
@article{zhao2025deepmesh,
  title={DeepMesh: Auto-Regressive Artist-mesh Creation with Reinforcement Learning},
  author={Zhao, Ruowen and Ye, Junliang and Wang, Zhengyi and Liu, Guangce and Chen, Yiwen and Wang, Yikai and Zhu, Jun},
  journal={arXiv preprint arXiv:2503.15265},
  year={2025}
}
```
